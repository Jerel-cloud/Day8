{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9215f5c-525b-4508-8b0d-700f55cbd252",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "#### University of Redlands - DATA 101\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data101.joannabieri.com](https://joannabieri.com/data101.html)\n",
    "\n",
    "---------------------------------------\n",
    "# Homework Day 8\n",
    "---------------------------------------\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. Load data into Python that you find online\n",
    "2. Understand data types and fix some errors\n",
    "3. Find your own data to play with\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "This homework has **5 questions** and **1 problem**.\n",
    "\n",
    "NOTE: Be kind to yourself. Working with data can be hard! Every data set is different. **Seriously** come get help! Come to lab!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "049c24b6-a6c1-4ccc-b2de-5ea0366d09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.defaule = 'colab'\n",
    "\n",
    "from itables import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23773272-c059-4148-a5a8-91e9da594c46",
   "metadata": {},
   "source": [
    "## Try reading in some data - csv\n",
    "\n",
    "Go to the [Cal Fire Website](https://www.fire.ca.gov/incidents) and scroll to the bottom to see the Incident Data. We will download the file named **ALL DATA AS CSV** this should put the data file into your Downloads folder. \n",
    "\n",
    "Next you need to move the file **mapdataall.csv** from your Downloads folder into your Day8 folder where you are doing your homework. You can open your Downloads folder and drag the file into JupyterLab side bar. Then I can run the command\n",
    "\n",
    "    DF_raw = pd.read_csv('mapdataall.csv')\n",
    "\n",
    "to load the data and look at the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90fdd5f-bd17-4c94-b3f4-7ddc998bd001",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mapdataall.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m DF_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmapdataall.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m show(DF_raw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mapdataall.csv'"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "DF_raw = pd.read_csv('mapdataall.csv')\n",
    "show(DF_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeae6d6-55da-4b02-b5e5-51efcaf6d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e235e4-98f5-496f-818c-1ac35a321889",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(DF_raw['incident_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4223569-1a4a-4953-a860-fd0a3dc15d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(DF_raw,\n",
    "                 x='incident_acres_burned',\n",
    "                 nbins=10,\n",
    "                 color = 'calfire_incident')\n",
    "\n",
    "fig.update_layout(bargap=0.05,\n",
    "                  title='Amount of acres burned',\n",
    "                  title_x=0.3,\n",
    "                  yaxis_title=\"Frequency\",\n",
    "                  xaxis_title=\"fires\",\n",
    "                  autosize=False,\n",
    "                  width=700,\n",
    "                  height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3589fc-ded6-463c-8af5-f53328bf4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = DF_raw['incident_acres_burned'] > 500000\n",
    "DF_raw[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e4499-edd1-4210-b3ff-292dd2eb4df7",
   "metadata": {},
   "source": [
    "Q1 How many variables and observations?\r\n",
    "\r\n",
    "The data has 2,752 observations and 23 variables.\r\n",
    "\r\n",
    "Q2 How many different incident types are there?\r\n",
    "\r\n",
    "There are three incident types. Wildfire, Fire, and Flood.\r\n",
    "\r\n",
    "Q3 Make a histogram of the acres burned and color the bars by whether or not the incident was a calfire incident. You will probably need to make a mask to remove very small and very large fires. How many fires burned more than 100,000 acres? What is the largest fire in the data?\r\n",
    "\r\n",
    "There are 20 fires that have burned over 100,000 acres. The largest fire in the data is the August Complex (includes Doe Fire). This fire has burned 1032648.0 acres.\n",
    "\n",
    "**Extra Q** EXTRA - CHALLENGE - See if you can create a graph that answers the question: Are fires getting bigger or more frequent over time? You get complete creative control on how to answer this question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36876b-02c2-4d86-b55b-62819a368bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to write some code to answer the questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f769b-d87d-429a-9de8-c35af020525d",
   "metadata": {},
   "source": [
    "**(Click Here)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0388222e-a80b-4392-99cd-3966254c4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09683e-ac6a-4cb5-a47d-6cbf580524d2",
   "metadata": {},
   "source": [
    "## Try reading in some data from Wikipedia - html\n",
    "\n",
    "Here we will explore academy award winning films. Go to the [Wiki for the List of Academy Award Winning Films](https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films). Look at what type of data is there. How many tables? Any weird looking data?\n",
    "\n",
    "Now read the html data into Python and show the data in DF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b93dc3-265e-4cd7-b350-1a8599ca98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw = DF[0]\n",
    "show(DF_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76e487-75a1-4461-b6cc-d229fa154122",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd62d4d-675f-4706-9b79-993e5b5ad343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1942</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1931</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1932</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1928</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1929</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1930</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  count\n",
       "0   1945     21\n",
       "1   1949     20\n",
       "2   1942     20\n",
       "3   1950     19\n",
       "4   1948     19\n",
       "..   ...    ...\n",
       "91  1931     10\n",
       "92  1932      9\n",
       "93  1928      7\n",
       "94  1929      6\n",
       "95  1930      6\n",
       "\n",
       "[96 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is some helper code\n",
    "# This is code that will read in the data and then fix the Year column\n",
    "my_website = \"https://en.wikipedia.org/wiki/List_of_Academy_Award%E2%80%93winning_films\"\n",
    "DF = pd.read_html(my_website)\n",
    "DF_raw = DF[0]\n",
    "DF_raw['Year'] = DF_raw['Year'].apply(lambda x: int(x.split('/')[0]))\n",
    "DF_raw['Year'].value_counts().reset_index().rename(columns={\"index\": \"value\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70b364-4c59-4631-87a4-552d7abaac2a",
   "metadata": {},
   "source": [
    "**Q4** Following along with the lecture notes or video, fix the data in the 'Awards' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57571cc2-dbca-4354-b0db-676b03005f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "award_data = DF_raw['Awards'].value_counts()\n",
    "DF_award = award_data.reset_index().rename(columns={\"index\": \"value\", 0: \"count\"})\n",
    "DF_award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51c0742-d796-4f63-a3e9-c98cdec76247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "DF_raw['Awards'] = DF_raw['Awards'].apply(lambda x: int(x.split('(')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5ce86-e820-481b-a8c8-ab5f063b0ad5",
   "metadata": {},
   "source": [
    "**Q5** Now try to fix the data in the \"Nominations\" column - see if you can do it without looking at the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3af04-d2bd-4304-9374-b36c25d155da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_data = DF_raw['Nominations'].value_counts()\n",
    "DF_nom = nom_data.reset_index().rename(columns={\"index\": \"value\", 0: \"count\"})\n",
    "show(DF_nom)\n",
    "print('I can see that I want the data to the left of the [ character')\n",
    "\n",
    "DF_raw['Nominations'] = DF_raw['Nominations'].apply(lambda x: int(x.split('[')[0]))\n",
    "award_data = DF_raw['Awards'].value_counts()\n",
    "DF_award = award_data.reset_index().rename(columns={\"index\": \"value\", 0: \"count\"})\n",
    "show(DF_award)\n",
    "\n",
    "DF_raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c8227-7b3e-4067-9b49-bd9c58752402",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Your homework today will be to see if you can find some data of your own. This can be the first steps you take toward your final project. \n",
    "\n",
    "You should:\n",
    "\n",
    "* Find some data online\n",
    "* Read that data into Python using the Pandas commands we learned\n",
    "* Look at the DataFrame - number of variables, number of observations, AND the dtypes. Comment on what you see.\n",
    "* Try to do summary statistics (.describe()). Does it work like expected?\n",
    "* Attempt to fix any data, or explain why the data does not need to be fixed.\n",
    "* Make some sort of graph using columns in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ad570-5dfa-46a0-86c8-f4610bacaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw2 = pd.read_csv('U.S._Chronic_Disease_Indicators__CDI___2023_Release.csv')\n",
    "show(DF_raw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6098a1e-a894-4b45-a105-c4d599b11ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_raw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e1280-b9fb-4e3e-967d-ae9eb87b7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = list(DF_raw2.keys())\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c7d64-2753-48dd-a462-88843e7ff56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_columns = ['LowConfidenceLimit', 'HighConfidenceLimit']\n",
    "DF_raw2[my_columns].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e4032-597a-457f-8bb4-5c9c4d606c0c",
   "metadata": {},
   "source": [
    "This is data for indicators of chronic diseases. There are 1185676 observations and 34 variables. Most of the stratification categories seems to be NaN. I'm using .describe to describe to me the confidence limits which seem to be the confidence in which people are feeling they have with being diagnosed. The 'StratificationCategoryID2', 'StratificationID2', 'StratificationCategoryID3', 'StratificationID3', and 'TopicID' categories need to be fixed. This is because all of them are filled with NaN. I beilieve that I need more practice/help learning with these concepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
